import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score

# ðŸ”¹ Step 1: Define the dataset (Improved version with more samples)
data = pd.DataFrame({
    "text": [
        "Team A won the championship!", 
        "Government passes new law", 
        "Player X scores a goal", 
        "Election results are in", 
        "Local team wins again", 
        "Debate on healthcare reform", 
        "Match ends in a tie", 
        "New policies introduced by the government",
    ],
    "label": ["Sports", "Politics", "Sports", "Politics", "Sports", "Politics", "Sports", "Politics", ]
})

# ðŸ”¹ Step 2: Stratified Train-Test Split (Ensuring class balance)
X_train, X_test, y_train, y_test = train_test_split(
    data["text"], data["label"], test_size=0.25, stratify=data["label"], random_state=42
)

# ðŸ”¹ Step 3: Convert text to TF-IDF features (Improved settings)
vectorizer = TfidfVectorizer(stop_words="english", ngram_range=(1, 2), max_features=1000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# ðŸ”¹ Step 4: Train NaÃ¯ve Bayes Classifier
nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)

# ðŸ”¹ Step 5: Make Predictions
y_pred = nb_model.predict(X_test_tfidf)

# ðŸ”¹ Step 6: Evaluate Performance
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')

# ðŸ”¹ Step 7: Print Results
print(f'Accuracy: {accuracy:.2f}')
print(f'Precision: {precision:.2f}')
print(f'Recall: {recall:.2f}')
print("\nPredictions:")

# ðŸ”¹ Step 8: Display predictions with true labels
for text, true_label, pred in zip(X_test, y_test, y_pred):
    print(f'Text: "{text}" - True Label: {true_label}, Predicted Label: {pred}')
